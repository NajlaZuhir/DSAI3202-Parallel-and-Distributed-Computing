{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Parallelism with Machine Learning: The Housing Prices Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the competition\n",
    "\n",
    "- The Housing Prices Competition train_dataset consists of various features of residential homes in Ames, Iowa, including both quantitative and categorical variables like the size of the property, the number of rooms, year built, and neighborhood quality.\n",
    "- It includes a set of 79 explanatory variables describing almost every aspect of the houses, allowing for in-depth analysis.\n",
    "- *The primary goal* of the competition is to predict **the final price of each home**, in this lab we will use *RandomForests*.\n",
    "- The models are evaluated on Root Mean Squared Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price, encouraging precise predictions over a range of housing prices.\n",
    "\n",
    "### File descriptions\n",
    "- *train.csv*: the training set used to train the model.\n",
    "- *test.csv*: the test set used to compute the performance of the model.\n",
    "- *train_data_description.txt*: full description of each column.\n",
    "### Useful train_data fields\n",
    "\n",
    "Here's a brief version of what you'll find in the train_data description file.\n",
    "\n",
    "- *SalePrice*: the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "- *MSSubClass*: The building class\n",
    "- *MSZoning*: The general zoning classification\n",
    "\n",
    "Teh train_dataset is acessible here: https://www.kaggle.com/code/dansbecker/random-forests/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare the train_data\n",
    "*If you're curious about this the professor can explain it for you*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  \\\n",
      "Id                                                                              \n",
      "1           60         3         65.0     8450       1         3            3   \n",
      "2           20         3         80.0     9600       1         3            3   \n",
      "3           60         3         68.0    11250       1         0            3   \n",
      "4           70         3         60.0     9550       1         0            3   \n",
      "5           60         3         84.0    14260       1         0            3   \n",
      "\n",
      "    Utilities  LotConfig  LandSlope  ...  GarageQual  GarageCond  PavedDrive  \\\n",
      "Id                                   ...                                       \n",
      "1           0          4          0  ...           4           4           2   \n",
      "2           0          2          0  ...           4           4           2   \n",
      "3           0          4          0  ...           4           4           2   \n",
      "4           0          0          0  ...           4           4           2   \n",
      "5           0          2          0  ...           4           4           2   \n",
      "\n",
      "    WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
      "Id                                                                             \n",
      "1            0           61              0          0            0         0   \n",
      "2          298            0              0          0            0         0   \n",
      "3            0           42              0          0            0         0   \n",
      "4            0           35            272          0            0         0   \n",
      "5          192           84              0          0            0         0   \n",
      "\n",
      "    MiscVal  \n",
      "Id           \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "5         0  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the train_dataset\n",
    "file_path = '../data/train.csv'\n",
    "train_data = pd.read_csv(file_path, index_col=\"Id\")\n",
    "\n",
    "# Columns to be deleted\n",
    "columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "# Delete the specified columns\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_delete, axis=1)\n",
    "\n",
    "# Define the input features (X) and the output (y)\n",
    "X = train_data_cleaned.drop('SalePrice', axis=1)\n",
    "y = train_data_cleaned['SalePrice']\n",
    "\n",
    "# Identify the categorical columns in X\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize a LabelEncoder for each categorical column\n",
    "label_encoders = {column: LabelEncoder() for column in categorical_columns}\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    X[column] = label_encoders[column].fit_transform(X[column])\n",
    "\n",
    "# Display the first few rows of X to confirm the encoding\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 70), (438, 70), (1022,), (438,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the first dataset (X, y) into train and test sets with a 70% - 30% split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Fill NaN values in X_train and X_val with the median of the respective columns\n",
    "X_train_filled = X_train.fillna(X_train.median())\n",
    "X_val_filled = X_val.fillna(X_val.median())\n",
    "\n",
    "(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First RandomForest Model\n",
    "This is the code for a simple trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation data: 26057.941851126383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_filled = rf_model.predict(X_val_filled)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_filled = sqrt(mean_squared_error(y_val, y_val_pred_filled))\n",
    "\n",
    "# Print the RMSE\n",
    "print(f'RMSE on the validation data: {rmse_filled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of Random Forest Model\n",
    "The three most important parameters that typically have the most impact on the performance of a Random Forest model are:\n",
    "\n",
    "- *n_estimators*: This parameter specifies the number of trees in the forest. Generally, a higher number of trees increases the performance and makes the predictions more stable, but it also makes the computation slower. Selecting the right number of trees requires balancing between performance and computational efficiency.\n",
    "\n",
    "- *max_features*: This parameter defines the maximum number of features that are allowed to try in an individual tree. There are several options available for this parameter:\n",
    "\n",
    "    - *sqrt*: This is commonly used and means that the maximum number of features used at each split is the square root of the total number of features.\n",
    "    - *log2*: This is another typical option, meaning the log base 2 of the feature count is used.\n",
    "    - *A specific integer or float*: You can specify an exact number or a proportion of the total.\n",
    "\n",
    "- *max_depth*: This parameter specifies the maximum depth of each tree. Deeper trees can model more complex patterns, but they also risk overfitting. Limiting the depth of trees can improve the model's generalization and reduce overfitting. It's often useful to set this parameter to a finite value, especially when dealing with a large number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best parameters sequentially\n",
    "<span style=\"color:red\">This code only looks for the best paramters. It is NOT best modeling practieces.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define the parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]  # None means using all features\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]  # None means no limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, sqrt, 5. RMSE: 34018.6946431472, MAPE: 13.846204059816515%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30158.362616471855, MAPE: 11.1847373574493%\n",
      "The parameters: 10, sqrt, 20. RMSE: 30593.76147467334, MAPE: 11.148658516638926%\n",
      "The parameters: 10, sqrt, None. RMSE: 28608.440009540453, MAPE: 11.124252485645316%\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, log2, 5. RMSE: 34956.394381827566, MAPE: 13.945831547616713%\n",
      "The parameters: 10, log2, 10. RMSE: 30136.927641357106, MAPE: 11.160840785213171%\n",
      "The parameters: 10, log2, 20. RMSE: 30841.310557247474, MAPE: 11.240205002153882%\n",
      "The parameters: 10, log2, None. RMSE: 29000.351214559596, MAPE: 10.98098439114081%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 10, None, 5. RMSE: 30977.339419939668, MAPE: 12.32718845204275%\n",
      "The parameters: 10, None, 10. RMSE: 26371.732325187742, MAPE: 10.387601696539232%\n",
      "The parameters: 10, None, 20. RMSE: 27582.089072839033, MAPE: 10.336644923118392%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▏                                                                        | 1/7 [00:00<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 10, None, None. RMSE: 28062.104755431203, MAPE: 10.28772353916743%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32317.961786662752, MAPE: 13.114437916762203%\n",
      "The parameters: 25, sqrt, 10. RMSE: 28259.543521821943, MAPE: 10.47369873275887%\n",
      "The parameters: 25, sqrt, 20. RMSE: 28601.996953881055, MAPE: 10.651671775420226%\n",
      "The parameters: 25, sqrt, None. RMSE: 28437.477716170713, MAPE: 10.650717147533856%\n",
      "The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, log2, 5. RMSE: 34640.741335575985, MAPE: 13.585957690083541%\n",
      "The parameters: 25, log2, 10. RMSE: 29797.647023472127, MAPE: 10.802129162615948%\n",
      "The parameters: 25, log2, 20. RMSE: 28152.423144151206, MAPE: 10.113221227840645%\n",
      "The parameters: 25, log2, None. RMSE: 28624.714349076796, MAPE: 10.195238945186857%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 25, None, 5. RMSE: 30622.018751108048, MAPE: 12.284801453967585%\n",
      "The parameters: 25, None, 10. RMSE: 27253.405412634103, MAPE: 10.272632581222856%\n",
      "The parameters: 25, None, 20. RMSE: 26499.315199813544, MAPE: 10.019023380641842%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████▎                                                            | 2/7 [00:02<00:05,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 25, None, None. RMSE: 27011.528848190042, MAPE: 10.057567711051357%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%\n",
      "The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "The parameters: 50, sqrt, 5. RMSE: 32807.733869677046, MAPE: 12.765423020132053%\n",
      "The parameters: 50, sqrt, 10. RMSE: 28193.908384996157, MAPE: 10.30283712157863%\n",
      "The parameters: 50, sqrt, 20. RMSE: 28322.13190140527, MAPE: 10.266831234466041%\n",
      "The parameters: 50, sqrt, None. RMSE: 28253.30753002766, MAPE: 10.301610941463089%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%\n",
      "The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 50, log2, 5. RMSE: 35272.23782970266, MAPE: 13.259237055635129%\n",
      "The parameters: 50, log2, 10. RMSE: 29337.548793235695, MAPE: 10.69972715022594%\n",
      "The parameters: 50, log2, 20. RMSE: 28219.379219234233, MAPE: 10.054841695082303%\n",
      "The parameters: 50, log2, None. RMSE: 28552.120501147994, MAPE: 10.110335561128336%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "The parameters: 50, None, 5. RMSE: 30578.268789069476, MAPE: 12.246352597445519%\n",
      "The parameters: 50, None, 10. RMSE: 26549.03681495154, MAPE: 10.164540522209597%\n",
      "The parameters: 50, None, 20. RMSE: 26616.753965688236, MAPE: 9.95616179407857%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████▍                                                | 3/7 [00:04<00:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 50, None, None. RMSE: 26659.206888314602, MAPE: 9.950072723845874%\n",
      "The parameters: 100, sqrt, 1. RMSE: 60511.413390408285, MAPE: 24.970655834062548%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48423.20979308409, MAPE: 19.124218836706603%\n",
      "The parameters: 100, sqrt, 5. RMSE: 32585.44117019146, MAPE: 12.510275320688514%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27940.66308571875, MAPE: 10.232467246501514%\n",
      "The parameters: 100, sqrt, 20. RMSE: 27530.724415300712, MAPE: 10.125866760621907%\n",
      "The parameters: 100, sqrt, None. RMSE: 27690.85111196373, MAPE: 10.111048513592108%\n",
      "The parameters: 100, log2, 1. RMSE: 62166.92632864128, MAPE: 25.90574767935297%\n",
      "The parameters: 100, log2, 2. RMSE: 49946.811096505524, MAPE: 19.85047840173841%\n",
      "The parameters: 100, log2, 5. RMSE: 34438.66151846642, MAPE: 13.17388786526951%\n",
      "The parameters: 100, log2, 10. RMSE: 28459.288873741767, MAPE: 10.547559689956204%\n",
      "The parameters: 100, log2, 20. RMSE: 27471.51821338425, MAPE: 9.805906069975684%\n",
      "The parameters: 100, log2, None. RMSE: 27735.747830866087, MAPE: 10.003262143296658%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 100, None, 5. RMSE: 30154.47423520161, MAPE: 12.085654020145233%\n",
      "The parameters: 100, None, 10. RMSE: 26265.099994067186, MAPE: 10.040721857978957%\n",
      "The parameters: 100, None, 20. RMSE: 26152.741599610163, MAPE: 9.913529753089874%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████▌                                    | 4/7 [00:10<00:09,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 100, None, None. RMSE: 26057.941851126383, MAPE: 9.868196740754167%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60592.20080413971, MAPE: 25.348413331204604%\n",
      "The parameters: 200, sqrt, 2. RMSE: 48456.200987649645, MAPE: 19.31834333556386%\n",
      "The parameters: 200, sqrt, 5. RMSE: 32921.85786148226, MAPE: 12.593595077314337%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28088.902620554447, MAPE: 10.205458456989026%\n",
      "The parameters: 200, sqrt, 20. RMSE: 27532.91156851607, MAPE: 9.99674498484024%\n",
      "The parameters: 200, sqrt, None. RMSE: 27430.923405573616, MAPE: 10.001128964051244%\n",
      "The parameters: 200, log2, 1. RMSE: 62120.39237086007, MAPE: 26.338849401949805%\n",
      "The parameters: 200, log2, 2. RMSE: 50047.12857344109, MAPE: 20.132262501400174%\n",
      "The parameters: 200, log2, 5. RMSE: 34734.445288631454, MAPE: 13.310668983679474%\n",
      "The parameters: 200, log2, 10. RMSE: 28692.19328330196, MAPE: 10.425408664401772%\n",
      "The parameters: 200, log2, 20. RMSE: 27918.172300177175, MAPE: 9.871948875899832%\n",
      "The parameters: 200, log2, None. RMSE: 28122.610919892722, MAPE: 10.075865891296619%\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%\n",
      "The parameters: 200, None, 5. RMSE: 30056.99415042013, MAPE: 12.027413013145498%\n",
      "The parameters: 200, None, 10. RMSE: 26485.54967760915, MAPE: 9.968649121179467%\n",
      "The parameters: 200, None, 20. RMSE: 26191.615393143096, MAPE: 9.814804116215956%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████████▋                        | 5/7 [00:21<00:12,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 200, None, None. RMSE: 26109.529848542985, MAPE: 9.785264413857124%\n",
      "The parameters: 300, sqrt, 1. RMSE: 60929.66932059552, MAPE: 25.5233017132497%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48477.515732693806, MAPE: 19.45952457308847%\n",
      "The parameters: 300, sqrt, 5. RMSE: 32739.920144412845, MAPE: 12.654260849343446%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27720.206311955073, MAPE: 10.158753220059861%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27459.785134152986, MAPE: 9.886952721263405%\n",
      "The parameters: 300, sqrt, None. RMSE: 27394.84596466395, MAPE: 9.923924926914179%\n",
      "The parameters: 300, log2, 1. RMSE: 62683.20415726862, MAPE: 26.538128720991566%\n",
      "The parameters: 300, log2, 2. RMSE: 50458.67950947336, MAPE: 20.275483738507045%\n",
      "The parameters: 300, log2, 5. RMSE: 34565.6574161325, MAPE: 13.300516763849002%\n",
      "The parameters: 300, log2, 10. RMSE: 28541.379624482677, MAPE: 10.42483342213683%\n",
      "The parameters: 300, log2, 20. RMSE: 27744.585234343336, MAPE: 9.924986717080374%\n",
      "The parameters: 300, log2, None. RMSE: 27972.716859688764, MAPE: 10.050994009021618%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 300, None, 5. RMSE: 30053.282347030145, MAPE: 12.040192412613166%\n",
      "The parameters: 300, None, 10. RMSE: 26435.067646149004, MAPE: 9.957708448691804%\n",
      "The parameters: 300, None, 20. RMSE: 26224.452972222785, MAPE: 9.831241564947488%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████▊            | 6/7 [00:37<00:09,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 300, None, None. RMSE: 26176.10432944751, MAPE: 9.801826393115594%\n",
      "The parameters: 400, sqrt, 1. RMSE: 60914.53857642404, MAPE: 25.51869058914844%\n",
      "The parameters: 400, sqrt, 2. RMSE: 48669.695843852176, MAPE: 19.530745286106946%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32809.62783027221, MAPE: 12.71009467191943%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27744.18030444477, MAPE: 10.125160913453673%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27497.671359831445, MAPE: 9.905124417060355%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.113736521427, MAPE: 9.945984648595795%\n",
      "The parameters: 400, log2, 1. RMSE: 62661.54638863782, MAPE: 26.43424504101804%\n",
      "The parameters: 400, log2, 2. RMSE: 50422.97022602301, MAPE: 20.23343384859187%\n",
      "The parameters: 400, log2, 5. RMSE: 34496.868353168815, MAPE: 13.290480205939964%\n",
      "The parameters: 400, log2, 10. RMSE: 28518.64779526882, MAPE: 10.390264584164836%\n",
      "The parameters: 400, log2, 20. RMSE: 27800.35162861101, MAPE: 9.91776916154931%\n",
      "The parameters: 400, log2, None. RMSE: 27905.32754903062, MAPE: 10.017981777351737%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 400, None, 5. RMSE: 30246.733688359316, MAPE: 12.052665031964972%\n",
      "The parameters: 400, None, 10. RMSE: 26626.130211240506, MAPE: 9.967897691949654%\n",
      "The parameters: 400, None, 20. RMSE: 26466.61626732859, MAPE: 9.851633812842412%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:58<00:00,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 400, None, None. RMSE: 26362.199455330487, MAPE: 9.83203095544113%\n",
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE: 9.83203095544113%\n",
      "The sequential execution time is 59.00056791305542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Starting the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize variables to store the best model and its RMSE and parameters\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "best_model = None\n",
    "best_parameters = {}\n",
    "\n",
    "# Loop over all possible combinations of parameters\n",
    "for n_estimators in tqdm(n_estimators_range):\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # Create and train the Random Forest model\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf_model.fit(X_train_filled, y_train)\n",
    "            \n",
    "            # Make predictions and compute RMSE\n",
    "            y_val_pred = rf_model.predict(X_val_filled)\n",
    "            rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "            print(f\"The parameters: {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "            # If the model is better than the current best, update the best model and its parameters\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_mape = mape\n",
    "                best_model = rf_model\n",
    "                best_parameters = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth\n",
    "                }\n",
    "print(f\"The best parameters {best_parameters} for RMSE = {best_rmse}, MAPE: {mape}%\")\n",
    "end_time = time.time()\n",
    "sequential_time = end_time - start_time\n",
    "print(f\"The sequential execution time is {sequential_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Using Threading\n",
    "\n",
    "This program is training a Random Forest model using threading to speed up the hyperparameter tuning process. \n",
    "The code performs the following steps:\n",
    "\n",
    "- **Import Libraries**: Essential libraries such as time, threading, and components from sklearn are imported.\n",
    "- **Define Parameter Ranges**: Sets of hyperparameters (n_estimators, max_features, max_depth) are defined for the model to iterate through.\n",
    "- **Define Evaluation Function**: A function evaluate_model is defined to:\n",
    "    - Train the Random Forest model with the given parameters.\n",
    "    - Predict and calculate the Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE) on the validation set.\n",
    "    - Store the results (parameters and performance metrics) in a shared list.\n",
    "- **Initialize Threads for Model Training**: For each combination of parameters, a new thread is started, calling evaluate_model.\n",
    "- **Wait for Threads to Complete**: The main thread waits for all the model training threads to complete.\n",
    "- **Find Best Parameters**: Once all threads are done, the best parameters are determined based on the lowest RMSE.\n",
    "- **Results and Execution Time**: The best parameters, along with RMSE and MAPE, are printed, and the total time taken for the thread-based parallel execution is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "# Function to evaluate a model and return the metrics\n",
    "def evaluate_model(n_estimators: int = 100, \n",
    "                   max_features: str = 'auto', \n",
    "                   max_depth: Union[int, None] = None, \n",
    "                   results: list = [], \n",
    "                   index: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Trains a Random Forest model with the provided hyperparameters, evaluates it on a validation set,\n",
    "    and stores the performance metrics and hyperparameters in a shared list.\n",
    "\n",
    "    Parameters:\n",
    "        n_estimators (int): The number of trees in the forest.\n",
    "        max_features (Union[str, None]): The number of features to consider when looking for the best split; \n",
    "                                         can be 'sqrt', 'log2', or None (use all features).\n",
    "        max_depth (Union[int, None]): The maximum depth of the tree; can be an integer or None (no limit).\n",
    "        results (List[Optional[Tuple]]): A shared list where the function's results (hyperparameters and performance metrics) are stored.\n",
    "        index (int): The position in the results list where the results of this function call should be stored.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return a value. It modifies the `results` list in place by adding the performance metrics and hyperparameters.\n",
    "\n",
    "    Note:\n",
    "        This function is designed to be run in a separate thread for each combination of hyperparameters,\n",
    "        facilitating parallel model evaluation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create and train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_filled, y_train)\n",
    "    \n",
    "    # Make predictions and compute RMSE\n",
    "    y_val_pred = rf_model.predict(X_val_filled)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    # Compute MAPE\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "    \n",
    "    # Store the results\n",
    "    results[index] = (n_estimators, max_features, max_depth, rmse, mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the threading program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finishing threads: 100%|██████████████████████████████████████████████████████████████| 126/126 [00:48<00:00,  2.58it/s]\n",
      "Anlyzing results: 100%|███████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 689025.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE = 9.868196740754167%\n",
      "The thread parallel execution time is 55.66719841957092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define the parameter ranges\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]  # None means using all features\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]  # None means no limit\n",
    "\n",
    "# Store results from each thread\n",
    "results = [None] * (len(n_estimators_range) * len(max_features_range) * len(max_depth_range))\n",
    "\n",
    "# Create and start threads for each combination of parameters\n",
    "threads = []\n",
    "index = 0\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            thread = Thread(target=evaluate_model, args=(n_estimators,\n",
    "                                                         max_features,\n",
    "                                                         max_depth,\n",
    "                                                         results,\n",
    "                                                         index))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "            index += 1\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in tqdm(threads, desc=\"Finishing threads: \"):\n",
    "    thread.join()\n",
    "\n",
    "# Find the best parameters based on RMSE\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "for n_estimators, max_features, max_depth, rmse, mape in tqdm(results, desc=\"Anlyzing results: \"):\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_mape = mape\n",
    "        best_params = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_features': max_features,\n",
    "            'max_depth': max_depth\n",
    "        }\n",
    "\n",
    "print(f\"The best parameters {best_params} for RMSE = {best_rmse}, MAPE = {best_mape}%\")\n",
    "end_time = time.time()\n",
    "threading_time = end_time - start_time\n",
    "print(f\"The thread parallel execution time is {threading_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Processes\n",
    "\n",
    "1. **Start Timing**:\n",
    "    - Record the current time to calculate the total execution time once all processes complete.\n",
    "\n",
    "2. **Prepare for Parallel Execution**:\n",
    "    - Initialize empty lists to keep track of the Process objects (processes) and the file paths where each process's output will be stored (`file_paths`).\n",
    "\n",
    "3. **Iterate Over Parameter Combinations**: \n",
    "    - Loop through each combination of hyperparameters defined by `n_estimators_range`, `max_features_range`, and `max_depth_range`.\n",
    "    - For each combination, create a unique file path to store the evaluation results. This ensures that each process's output is saved separately and can be identified easily.\n",
    "\n",
    "4. **Create and Start Processes**:\n",
    "    - For every combination of parameters, instantiate a Process object from the multiprocessing module, targeting the `evaluate_model` function with the current combination of parameters and the designated file path for results.\n",
    "    - Add the created Process object to the processes list for tracking and start the process using `process.start()`. This begins the model evaluation in a separate process.\n",
    "\n",
    "5. **Wait for Process Completion**:\n",
    "    - After starting all processes, loop through the processes list and call `process.join()` on each. This ensures the main program waits for all processes to finish their execution before moving forward.\n",
    "\n",
    "6. **Collect and Clean Up Results**:\n",
    "    - Iterate over the file_paths list to locate and open each results file created by the processes.\n",
    "    - Load the evaluation results from each file into a Python object (e.g., a dictionary) and append it to the results list for further analysis.\n",
    "    - Delete the results file to clean up the file system, ensuring no residual files remain.\n",
    "\n",
    "7. **Analyze Results (Not fully shown in the snippet)**:\n",
    "    - Process the collected results to identify the best parameter combination based on the evaluation metrics, such as the lowest Root Mean Squared Error (RMSE) or Mean Absolute Percentage Error (MAPE).\n",
    "\n",
    "8. **Report Best Parameters and Performance Metrics**:\n",
    "    - Output the best performing model's parameters and its corresponding evaluation metrics to the console.\n",
    "\n",
    "9. **Calculate Total Execution Time**:\n",
    "    - Record the current time again at the end of the execution and calculate the total duration by subtracting the start time from this end time.\n",
    "    - Print the total parallel execution time to provide insight into the efficiency gained through parallel processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrinting the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to evaluate a model and save the results to a file\n",
    "def evaluate_model(n_estimators: int = 100, \n",
    "                   max_features: str = 'auto', \n",
    "                   max_depth: int = 1, \n",
    "                   file_path: str = 'model_results.json') -> None:\n",
    "    \"\"\"\n",
    "    Trains a Random Forest regressor with the specified hyperparameters,\n",
    "    evaluates its performance on a validation set, and saves the results to a file.\n",
    "\n",
    "    Parameters:\n",
    "        n_estimators (int): The number of trees in the forest. Default is 100.\n",
    "        max_features (Union[str, None]): The number of features to consider when looking for the best split.\n",
    "                                         Can be 'auto', 'sqrt', 'log2', or None. Default is 'auto'.\n",
    "        max_depth (Union[int, None]): The maximum depth of the trees. Default is None, meaning no limit.\n",
    "        file_path (str): Path to the file where the results will be saved. Default is 'model_results.json'.\n",
    "\n",
    "    This function does not return any value. It writes the model's performance metrics and the hyperparameters\n",
    "    used for training into a JSON file specified by file_path.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create and train the Random Forest model with given hyperparameters\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42  # Ensures reproducible results\n",
    "    )\n",
    "    rf_model.fit(X_train_filled, y_train)  # Assuming X_train_filled and y_train are pre-defined\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = rf_model.predict(X_val_filled)  # Assuming X_val_filled is pre-defined\n",
    "    \n",
    "    # Calculate the Root Mean Squared Error (RMSE)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))  # Assuming y_val is pre-defined\n",
    "    \n",
    "    # Calculate the Mean Absolute Percentage Error (MAPE)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100  # Assuming y_val is pre-defined\n",
    "    \n",
    "    # Prepare the results dictionary\n",
    "    result_dictionary = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape\n",
    "    }\n",
    "    \n",
    "    # Save the results dictionary to a file in JSON format\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(result_dictionary, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the multiprocesses program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finishing processes: 100%|████████████████████████████████████████████████████████████| 126/126 [00:15<00:00,  7.88it/s]\n",
      "Anlyzing results: 100%|█████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 3033.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters {'n_estimators': 100, 'max_features': None, 'max_depth': None} for RMSE = 26057.941851126383, MAPE = 9.868196740754167%\n",
      "The processes parallel execution time is 26.382996559143066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start timing the execution\n",
    "start_time = time.time()  \n",
    "\n",
    "# Initialize lists to keep track of processes and file paths for results\n",
    "processes = []\n",
    "file_paths = []\n",
    "\n",
    "# Assuming n_estimators_range, max_features_range, and max_depth_range are predefined lists\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # Construct a file path for each combination of parameters\n",
    "            file_path = f'results_{n_estimators}_{max_features}_{max_depth}.json'\n",
    "            # Create a process targeting the evaluate_model function with the current combination of parameters\n",
    "            process = Process(target=evaluate_model,\n",
    "                              args=(n_estimators,\n",
    "                                    max_features,\n",
    "                                    max_depth,\n",
    "                                    file_path))\n",
    "            processes.append(process)  # Add the process to the list\n",
    "            file_paths.append(file_path)  # Keep track of where the results will be stored\n",
    "            process.start()  # Start the process\n",
    "\n",
    "# Wait for all processes to complete\n",
    "for process in tqdm(processes, desc=\"Finishing processes: \"):\n",
    "    process.join()\n",
    "\n",
    "# Gather the results from each file\n",
    "results = []\n",
    "for file_path in tqdm(file_paths, desc=\"Anlyzing results: \"):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            results.append(json.load(f))  # Load the results and add them to the list\n",
    "        os.remove(file_path)  # Clean up by removing the file after reading\n",
    "    else:\n",
    "        print(f\"Warning: Missing results file {file_path}\")\n",
    "\n",
    "# Assuming there is logic here to process 'results' and find the best parameters based on RMSE\n",
    "\n",
    "# Output the best parameters and performance metrics\n",
    "print(f\"The best parameters {best_params} for RMSE = {best_rmse}, MAPE = {best_mape}%\")\n",
    "\n",
    "end_time = time.time()  # End timing the execution\n",
    "processes_time = end_time - start_time\n",
    "print(f\"The processes parallel execution time is {processes_time}\")  # Print the total parallel execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speedup\n",
    "Speedup in the context of parallel computing is a measure used to quantify the performance improvement of a parallel algorithm over a serial algorithm for solving a particular problem. Specifically, it tells us how much faster a parallel algorithm runs compared to its serial counterpart. The concept of speedup is crucial for understanding the benefits and efficiency of parallel processing.\n",
    "\n",
    "Mathematically, speedup (S) is defined as:\n",
    "\n",
    "$$\n",
    "S = \\frac{T_{serial}}{T_{parallel}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $T_{serial}$ is the execution time of the best-known serial algorithm for solving a problem.\n",
    "- $T_{parallel}$ is the execution time of the parallel algorithm solving the same problem with $np$ processors or cores.\n",
    "\n",
    "##### Interpretation\n",
    "\n",
    "- $S > 1$: The parallel algorithm is faster than the serial algorithm. The larger the value of $S$, the better the performance improvement.\n",
    "- $S = 1$: The parallel algorithm offers no speed improvement over the serial algorithm. This situation may occur due to overheads in parallelization that negate the benefits of running computations in parallel.\n",
    "- $S < 1$: The parallel algorithm is slower than the serial algorithm, which indicates a poor parallelization strategy where the overheads dominate the computational benefits.\n",
    "\n",
    "##### Ideal and Realistic Speedup\n",
    "\n",
    "- **Linear Speedup**: Ideally, if a problem is perfectly parallelizable, speedup would be equal to $np$ (the number of processors), meaning the task would run $np$ times faster than the serial version. This is known as linear speedup.\n",
    "- **Superlinear Speedup**: In some rare cases, speedup can be greater than $np$, which is known as superlinear speedup. This can happen due to several factors, such as more efficient use of cache memory in the parallel algorithm.\n",
    "- **Sublinear Speedup**: More commonly, the speedup is less than $np$ due to overheads such as communication among processors, synchronization, and data distribution. This is known as sublinear speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of the available CPUs is 4\n",
      "The speedup in the threading case is 1.0598803171009337.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "# Get the number of CPUs available\n",
    "number_of_cpus = multiprocessing.cpu_count()\n",
    "print(f\"The number of the available CPUs is {number_of_cpus}\")\n",
    "\n",
    "# Computing the speedup:\n",
    "speedup_threading = sequential_time / threading_time\n",
    "print(f\"The speedup in the threading case is {speedup_threading}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speedup in the multiprocessing case is 2.236310336499994.\n"
     ]
    }
   ],
   "source": [
    "speedup_processes = sequential_time / processes_time\n",
    "print(f\"The speedup in the multiprocessing case is {speedup_processes}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "Efficiency in the context of parallel computing is a measure that evaluates how well the computational resources (processors or cores) are utilized when executing a parallel algorithm. It's a way to quantify the effectiveness of parallelization by considering both the speedup achieved and the number of processors used.\n",
    "\n",
    "\n",
    "Efficiency (E) is defined as the speedup (S) divided by the number of processors ($n$) used in the parallel algorithm:\n",
    "\n",
    "$$E = \\frac{S}{np} = \\frac{T_{serial}}{T_{parallel} \\times np}$$\n",
    "\n",
    "Where:\n",
    "- $S$ is the speedup, which is the ratio of the execution time of the best serial algorithm ($T_{serial}$) to the execution time of the parallel algorithm ($T_{parallel}$).\n",
    "- $np$ is the number of processors (or cores) used in the parallel execution.\n",
    "\n",
    "#### Interpretation\n",
    "- **$E = 1$**: This is the ideal scenario where the parallel algorithm achieves perfect linear speedup, indicating that all processors are being used efficiently without any waste of computational resources.\n",
    "- **$0 < E < 1$**: This is the most common scenario, indicating sublinear speedup. It means that there are diminishing returns on adding more processors, likely due to overheads such as communication among processors, load imbalance, or idle time.\n",
    "- **$E > 1$**: Although rare, superlinear efficiency can occur, indicating that the parallel algorithm with $np$ processors is more than $np$ times faster than the serial algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The efficiency in the threading case is 0.2649700792752334.\n"
     ]
    }
   ],
   "source": [
    "# Computing the Efficiency for threading\n",
    "efficiency_threading = speedup_threading / number_of_cpus\n",
    "print(f\"The efficiency in the threading case is {efficiency_threading}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The efficiency in the threading case is 0.5590775841249985.\n"
     ]
    }
   ],
   "source": [
    "# Computing the Efficiency for multiprocessing\n",
    "efficiency_processes = speedup_processes / number_of_cpus\n",
    "print(f\"The efficiency in the threading case is {efficiency_processes}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amdahl's Law\n",
    "\n",
    "Amdahl's Law is used to find the maximum improvement to an overall system when only part of the system is improved. It is formulated as:\n",
    "\n",
    "$$\n",
    "S_{Amdahl} = \\frac{1}{(1 - P)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $P$ is the proportion of the execution time that the improved system affects (i.e., the parallelizable portion).\n",
    "\n",
    "# Interpretations of Amdahl's Law\n",
    "\n",
    "Amdahl's Law offers critical insights into the limits of parallel computing and system optimization. Here are the key interpretations:\n",
    "\n",
    "1. **Limited Speedup**: Amdahl's Law highlights that the speedup of a system due to parallelization is limited by the sequential portion of the task. Even if the parallelizable portion is executed infinitely fast, the speedup will have an upper limit determined by the sequential part.\n",
    "\n",
    "2. **Diminishing Returns**: As more processors are added, the benefit of adding additional processors decreases if the sequential portion of the task remains constant. This is because the speedup gains are primarily achieved in the parallelizable portion, which becomes a smaller fraction of the total execution time as it gets optimized.\n",
    "\n",
    "3. **Importance of Parallelizable Code**: The law emphasizes the importance of minimizing the sequential portion of a task to achieve significant speedup through parallelization. The more a task can be parallelized, the greater the potential speedup from adding more processors.\n",
    "\n",
    "4. **Bottleneck of Sequential Execution**: The sequential portion of a task acts as a bottleneck for overall system speedup. Reducing the sequential part through algorithm optimization or problem decomposition is crucial for enhancing performance in parallel computing environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: larger;\"><span style=\"color:red\">In the following the code runs for 1 iteration, showcasing is the part that **cannot** be made parallel.</span></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Amdhal speedup for threading\n",
    "# The seauenctial execution time\n",
    "print(f\"The sequential time is: {sequential_time}\")\n",
    "print(f\"Let's run only the sequential part that connot be parallelized: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The best parameters {'n_estimators': 10, 'max_features': 'sqrt', 'max_depth': 1} for RMSE = 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The sequential execution of non parallel time is 0.01868748664855957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Starting the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize variables to store the best model and its RMSE and parameters\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "best_model = None\n",
    "best_parameters = {}\n",
    "\n",
    "# # Loop over all possible combinations of parameters\n",
    "for n_estimators in tqdm(n_estimators_range[:1]):\n",
    "    for max_features in max_features_range[:1]:\n",
    "        for max_depth in max_depth_range[:1]:\n",
    "            # Create and train the Random Forest model\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf_model.fit(X_train_filled, y_train)\n",
    "            \n",
    "            # Make predictions and compute RMSE\n",
    "            y_val_pred = rf_model.predict(X_val_filled)\n",
    "            rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "            # Compute MAPE\n",
    "            mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "            print(f\"The parameters: {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "            # If the model is better than the current best, update the best model and its parameters\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_mape = mape\n",
    "                best_model = rf_model\n",
    "                best_parameters = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth\n",
    "                }\n",
    "print(f\"The best parameters {best_parameters} for RMSE = {best_rmse}, MAPE: {mape}%\")\n",
    "end_time = time.time()\n",
    "non_parallel_time = end_time - start_time\n",
    "print(f\"The sequential execution of non parallel time is {non_parallel_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speedup according to Amdhal should be 3157.2232811519043.\n"
     ]
    }
   ],
   "source": [
    "# Computing Amdhal speedup\n",
    "parallel_portion = 1 - (non_parallel_time / sequential_time)\n",
    "S_amdhal = 1 / (1 - parallel_portion)\n",
    "print(f\"The speedup according to Amdhal should be {S_amdhal}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amdahl's Law: the version dependant on the number of processors\n",
    "\n",
    "There is a second enhanced version of the law that measures the speedup according to the number of processors:\n",
    "\n",
    "$$\n",
    "S_{Amdahl} = \\frac{1}{(1 - P) + \\frac{P}{np}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $P$ is the proportion of the execution time that the improved system affects (i.e., the parallelizable portion).\n",
    "- $np$ is the speedup of the portion of the task that benefits from the improved system resources (i.e., the number of processors).\n",
    "\n",
    "#### Let's recompute the law for with the new formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speedup according to Amdhal should be 3.9962027999503804.\n"
     ]
    }
   ],
   "source": [
    "S_amdhal = 1 / ((1 - parallel_portion) + (parallel_portion / number_of_cpus))\n",
    "print(f\"The speedup according to Amdhal should be {S_amdhal}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"font-size: larger;\"><span style=\"color:green\">**See how this result is less theoritical and more realistic.**</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gustafson's Law\n",
    "\n",
    "Gustafson's Law provides a more optimistic view, suggesting that the speedup is linearly proportional to the number of processors when the workload scales with the number of processors. It is given by:\n",
    "\n",
    "$$\n",
    "\\text{Speedup} = (1 - P) + P \\cdot np = \\alpha + P \\cdot np\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $P$ and $np$ have the same meaning as in Amdahl's Law.\n",
    "- $\\alpha = 1 - P$: the serial part of the program.\n",
    "\n",
    "To compute these laws' predictions for speedup, we need:\n",
    "- The value of $P$ (the parallelizable portion of the task).\n",
    "- The number of processors $np$.\n",
    "\n",
    "# Interpretations of Gustafson's Law\n",
    "\n",
    "Gustafson's Law offers an optimistic perspective on the scalability of parallel computing, highlighting several key points:\n",
    "\n",
    "1. **Scalable Problem Size**: Unlike Amdahl's Law, which focuses on a fixed workload, Gustafson's Law assumes that the total workload can increase with the number of processors. This reflects more realistic scenarios where larger computational resources enable tackling more significant problems.\n",
    "\n",
    "2. **Linear Speedup**: Gustafson's Law suggests that the speedup of an algorithm can be nearly linear with respect to the number of processors, provided that the workload scales accordingly. This contrasts with Amdahl's Law, which predicts a theoretical upper limit to speedup due to the sequential portion of a task.\n",
    "\n",
    "3. **Reduced Impact of Sequential Components**: While Amdahl's Law emphasizes the limitation imposed by the sequential portion of a task, Gustafson's Law implies that increasing the problem size makes the fixed sequential time a smaller fraction of the total execution time, thus reducing its impact on the overall speedup.\n",
    "\n",
    "4. **Importance of Parallelizable Workload**: The law highlights the importance of designing algorithms and workloads that can be effectively parallelized. As the parallel portion of the workload increases, the potential for speedup grows, making efficient parallel algorithm design crucial for leveraging modern multi-processor systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speedup according to Gustafson should be 3.9990497979607875.\n"
     ]
    }
   ],
   "source": [
    "S_gustafson = (1 - parallel_portion) + (parallel_portion * number_of_cpus)\n",
    "print(f\"The speedup according to Gustafson should be {S_gustafson}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
